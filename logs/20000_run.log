[nltk_data] Downloading package punkt_tab to /home/bermar/nltk_data...
[nltk_data]   Package punkt_tab is already up-to-date!
[nltk_data] Downloading package stopwords to /home/bermar/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
2025-11-20 10:40:41.146299: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-20 10:40:41.171372: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-20 10:40:41.822423: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
nltk data downloaded successfully.

================================================================================
TWITTER SENTIMENT ANALYSIS PIPELINE
================================================================================
Started at: 2025-11-20 10:40:42
================================================================================
LOADING DATASET
================================================================================
Dataset shape: (162980, 2)
Columns: ['clean_text', 'category']

First 5 rows:
                                          clean_text  category
0  when modi promised “minimum government maximum...      -1.0
1  talk all the nonsense and continue all the dra...       0.0
2  what did just say vote for modi  welcome bjp t...       1.0

================================================================================
EXPLORATORY DATA ANALYSIS
================================================================================

1. Dataset Info:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 162980 entries, 0 to 162979
Data columns (total 2 columns):
 #   Column      Non-Null Count   Dtype  
---  ------      --------------   -----  
 0   clean_text  162976 non-null  object 
 1   category    162973 non-null  float64
dtypes: float64(1), object(1)
memory usage: 2.5+ MB
None

2. Missing values:
clean_text    4
category      7
dtype: int64

3. Sentiment Distribution:
   Negative   (-1):  35510 (21.79%)
   Neutral    ( 0):  55213 (33.88%)
   Positive   ( 1):  72250 (44.33%)

4. Text Statistics:
   Average text length: 124.17 characters
   Average word count: 20.08 words
   Max text length: 274 characters
   Min text length: 0 characters

================================================================================
DATA PREPROCESSING
================================================================================
Handling missing values...
Removed 11 empty texts
Preprocessing text (this may take a while)...
Removed 66 empty texts after preprocessing
Final dataset shape: (162903, 6)

================================================================================
DATASET SAMPLING FOR FASTER PROCESSING
================================================================================
Original dataset size: 162,903 samples
Sampling to: 20,000 samples

Target count per class for balancing: 6666
Final dataset size adjusted to: 19,998 samples (balanced)

Sampled dataset distribution:
   Negative  :   6666 (33.33%)
   Neutral   :   6666 (33.33%)
   Positive  :   6666 (33.33%)

New working dataset shape: (19998, 6)
Columns: ['clean_text', 'category', 'text_length', 'word_count', 'sentiment_label', 'processed_text']

################################################################################
TFIDF FEATURE PIPELINE
################################################################################

================================================================================
PREPARING TF-IDF FEATURES
================================================================================
TF-IDF training features shape: (15998, 5000)
TF-IDF test features shape: (4000, 5000)

================================================================================
TRAINING CLASSICAL MODELS WITH TFIDF FEATURES
================================================================================

1. Training Decision Tree with GridSearchCV...
   Best params: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}
   Accuracy: 0.6745
   F1-macro: 0.6724

2. Training KNN with GridSearchCV...
   Best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}
   Accuracy: 0.3810
   F1-macro: 0.2917

3. Training Logistic Regression with GridSearchCV...
   Best params: {'C': 10, 'max_iter': 100, 'solver': 'lbfgs'}
   Accuracy: 0.8127
   F1-macro: 0.8121

4. Training Voting Classifier (Ensemble)...
   Accuracy: 0.7170
   F1-macro: 0.7115

============================================================
EVALUATION RESULTS FOR DecisionTree (TF-IDF)
============================================================

Overall Metrics:
  Accuracy:  0.6745
  Precision: 0.6763
  Recall:    0.6745
  F1-Macro:  0.6724

Classification Report:
              precision    recall  f1-score   support

    Negative       0.68      0.59      0.64      1333
     Neutral       0.66      0.78      0.71      1333
    Positive       0.69      0.65      0.67      1334

    accuracy                           0.67      4000
   macro avg       0.68      0.67      0.67      4000
weighted avg       0.68      0.67      0.67      4000


============================================================
EVALUATION RESULTS FOR KNN (TF-IDF)
============================================================

Overall Metrics:
  Accuracy:  0.3810
  Precision: 0.5478
  Recall:    0.3811
  F1-Macro:  0.2917

Classification Report:
              precision    recall  f1-score   support

    Negative       0.65      0.11      0.19      1333
     Neutral       0.35      0.93      0.51      1333
    Positive       0.65      0.11      0.18      1334

    accuracy                           0.38      4000
   macro avg       0.55      0.38      0.29      4000
weighted avg       0.55      0.38      0.29      4000


============================================================
EVALUATION RESULTS FOR LogisticRegression (TF-IDF)
============================================================

Overall Metrics:
  Accuracy:  0.8127
  Precision: 0.8149
  Recall:    0.8128
  F1-Macro:  0.8121

Classification Report:
              precision    recall  f1-score   support

    Negative       0.82      0.77      0.79      1333
     Neutral       0.78      0.89      0.83      1333
    Positive       0.84      0.78      0.81      1334

    accuracy                           0.81      4000
   macro avg       0.81      0.81      0.81      4000
weighted avg       0.81      0.81      0.81      4000


============================================================
EVALUATION RESULTS FOR VotingClassifier (TF-IDF)
============================================================

Overall Metrics:
  Accuracy:  0.7170
  Precision: 0.7374
  Recall:    0.7170
  F1-Macro:  0.7115

Classification Report:
              precision    recall  f1-score   support

    Negative       0.80      0.57      0.67      1333
     Neutral       0.64      0.92      0.76      1333
    Positive       0.77      0.66      0.71      1334

    accuracy                           0.72      4000
   macro avg       0.74      0.72      0.71      4000
weighted avg       0.74      0.72      0.71      4000


################################################################################
WORD2VEC FEATURE PIPELINE
################################################################################

================================================================================
PREPARING WORD2VEC FEATURES
================================================================================
Training Word2Vec model...
Creating document vectors...
Word2Vec training features shape: (15998, 100)
Word2Vec test features shape: (4000, 100)

================================================================================
TRAINING CLASSICAL MODELS WITH WORD2VEC FEATURES
================================================================================

1. Training Decision Tree with GridSearchCV...
   Best params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
   Accuracy: 0.4525
   F1-macro: 0.4494

2. Training KNN with GridSearchCV...
   Best params: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}
   Accuracy: 0.4545
   F1-macro: 0.4561

3. Training Logistic Regression with GridSearchCV...
   Best params: {'C': 100, 'max_iter': 100, 'solver': 'liblinear'}
   Accuracy: 0.5347
   F1-macro: 0.5351

4. Training Voting Classifier (Ensemble)...
   Accuracy: 0.4998
   F1-macro: 0.4998

============================================================
EVALUATION RESULTS FOR DecisionTree (Word2Vec)
============================================================

Overall Metrics:
  Accuracy:  0.4525
  Precision: 0.4615
  Recall:    0.4525
  F1-Macro:  0.4494

Classification Report:
              precision    recall  f1-score   support

    Negative       0.43      0.58      0.49      1333
     Neutral       0.54      0.40      0.46      1333
    Positive       0.42      0.37      0.40      1334

    accuracy                           0.45      4000
   macro avg       0.46      0.45      0.45      4000
weighted avg       0.46      0.45      0.45      4000


============================================================
EVALUATION RESULTS FOR KNN (Word2Vec)
============================================================

Overall Metrics:
  Accuracy:  0.4545
  Precision: 0.4626
  Recall:    0.4545
  F1-Macro:  0.4561

Classification Report:
              precision    recall  f1-score   support

    Negative       0.42      0.48      0.45      1333
     Neutral       0.55      0.44      0.49      1333
    Positive       0.42      0.44      0.43      1334

    accuracy                           0.45      4000
   macro avg       0.46      0.45      0.46      4000
weighted avg       0.46      0.45      0.46      4000


============================================================
EVALUATION RESULTS FOR LogisticRegression (Word2Vec)
============================================================

Overall Metrics:
  Accuracy:  0.5347
  Precision: 0.5374
  Recall:    0.5348
  F1-Macro:  0.5351

Classification Report:
              precision    recall  f1-score   support

    Negative       0.49      0.55      0.52      1333
     Neutral       0.58      0.56      0.57      1333
    Positive       0.54      0.50      0.52      1334

    accuracy                           0.53      4000
   macro avg       0.54      0.53      0.54      4000
weighted avg       0.54      0.53      0.54      4000


============================================================
EVALUATION RESULTS FOR VotingClassifier (Word2Vec)
============================================================

Overall Metrics:
  Accuracy:  0.4998
  Precision: 0.5082
  Recall:    0.4998
  F1-Macro:  0.4998

Classification Report:
              precision    recall  f1-score   support

    Negative       0.46      0.57      0.51      1333
     Neutral       0.59      0.47      0.52      1333
    Positive       0.48      0.46      0.47      1334

    accuracy                           0.50      4000
   macro avg       0.51      0.50      0.50      4000
weighted avg       0.51      0.50      0.50      4000


################################################################################
NEURAL NETWORK PIPELINE
################################################################################

================================================================================
PREPARING DATA FOR NEURAL NETWORK
================================================================================
Neural network training data shape: (15998, 100)
Neural network test data shape: (4000, 100)
Number of unique tokens: 30820

================================================================================
TRAINING CNN-LSTM NEURAL NETWORK
================================================================================

Model Architecture:
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ embedding (Embedding)           │ (15998, 100, 128)      │     1,280,000 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d (Conv1D)                 │ (15998, 98, 64)        │        24,640 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling1d (MaxPooling1D)    │ (15998, 49, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (15998, 49, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (15998, 64)            │        33,024 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (15998, 32)            │         2,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (15998, 32)            │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (15998, 32)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (15998, 3)             │            99 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 1,339,971 (5.11 MB)
 Trainable params: 1,339,907 (5.11 MB)
 Non-trainable params: 64 (256.00 B)

Training model...
Epoch 1/10
Epoch 2/10
Epoch 3/10
Epoch 4/10
Epoch 5/10
Epoch 6/10
Epoch 7/10
Epoch 8/10
Epoch 9/10
Epoch 10/10


Test Loss: 0.4538
Test Accuracy: 0.8460
Test F1-Macro: 0.8459

============================================================
EVALUATION RESULTS FOR CNN-LSTM Neural Network
============================================================

Overall Metrics:
  Accuracy:  0.8460
  Precision: 0.8459
  Recall:    0.8460
  F1-Macro:  0.8459

Classification Report:
              precision    recall  f1-score   support

    Negative       0.84      0.82      0.83      1333
     Neutral       0.86      0.87      0.87      1333
    Positive       0.84      0.84      0.84      1334

    accuracy                           0.85      4000
   macro avg       0.85      0.85      0.85      4000
weighted avg       0.85      0.85      0.85      4000


================================================================================
MODEL COMPARISON SUMMARY
================================================================================

  Feature Type              Model Accuracy F1-Macro Precision Recall
Neural Network           CNN-LSTM   0.8460   0.8459    0.8459 0.8460
        TF-IDF LogisticRegression   0.8127   0.8121    0.8149 0.8128
        TF-IDF   VotingClassifier   0.7170   0.7115    0.7374 0.7170
        TF-IDF       DecisionTree   0.6745   0.6724    0.6763 0.6745
      Word2Vec LogisticRegression   0.5347   0.5351    0.5374 0.5348
      Word2Vec   VotingClassifier   0.4998   0.4998    0.5082 0.4998
      Word2Vec                KNN   0.4545   0.4561    0.4626 0.4545
      Word2Vec       DecisionTree   0.4525   0.4494    0.4615 0.4525
        TF-IDF                KNN   0.3810   0.2917    0.5478 0.3811

Comparison table saved to 'f20000_model_comparison.csv'

================================================================================
PLOTTING ROC CURVES
================================================================================

================================================================================
PIPELINE COMPLETED SUCCESSFULLY!
================================================================================
Completed at: 2025-11-20 10:46:45

================================================================================
BEST MODEL
================================================================================
Best performing model: CNN-LSTM with Neural Network features
  - Accuracy: 0.8460
  - F1-Macro: 0.8459

✅ Pipeline executed successfully!
