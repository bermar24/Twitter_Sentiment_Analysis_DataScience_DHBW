[nltk_data] Downloading package punkt_tab to /home/bermar/nltk_data...
[nltk_data]   Package punkt_tab is already up-to-date!
[nltk_data] Downloading package stopwords to /home/bermar/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
2025-11-20 10:35:11.051737: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-20 10:35:11.074716: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-20 10:35:11.661750: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
nltk data downloaded successfully.

================================================================================
TWITTER SENTIMENT ANALYSIS PIPELINE
================================================================================
Started at: 2025-11-20 10:35:11
================================================================================
LOADING DATASET
================================================================================
Dataset shape: (162980, 2)
Columns: ['clean_text', 'category']

First 5 rows:
                                          clean_text  category
0  when modi promised â€œminimum government maximum...      -1.0
1  talk all the nonsense and continue all the dra...       0.0
2  what did just say vote for modi  welcome bjp t...       1.0

================================================================================
EXPLORATORY DATA ANALYSIS
================================================================================

1. Dataset Info:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 162980 entries, 0 to 162979
Data columns (total 2 columns):
 #   Column      Non-Null Count   Dtype  
---  ------      --------------   -----  
 0   clean_text  162976 non-null  object 
 1   category    162973 non-null  float64
dtypes: float64(1), object(1)
memory usage: 2.5+ MB
None

2. Missing values:
clean_text    4
category      7
dtype: int64

3. Sentiment Distribution:
   Negative   (-1):  35510 (21.79%)
   Neutral    ( 0):  55213 (33.88%)
   Positive   ( 1):  72250 (44.33%)

4. Text Statistics:
   Average text length: 124.17 characters
   Average word count: 20.08 words
   Max text length: 274 characters
   Min text length: 0 characters

================================================================================
DATA PREPROCESSING
================================================================================
Handling missing values...
Removed 11 empty texts
Preprocessing text (this may take a while)...
Removed 66 empty texts after preprocessing
Final dataset shape: (162903, 6)

================================================================================
DATASET SAMPLING FOR FASTER PROCESSING
================================================================================
Original dataset size: 162,903 samples
Sampling to: 1,000 samples

Target count per class for balancing: 333
Final dataset size adjusted to: 999 samples (balanced)

Sampled dataset distribution:
   Negative  :    333 (33.33%)
   Neutral   :    333 (33.33%)
   Positive  :    333 (33.33%)

New working dataset shape: (999, 6)
Columns: ['clean_text', 'category', 'text_length', 'word_count', 'sentiment_label', 'processed_text']

################################################################################
TFIDF FEATURE PIPELINE
################################################################################

================================================================================
PREPARING TF-IDF FEATURES
================================================================================
TF-IDF training features shape: (799, 460)
TF-IDF test features shape: (200, 460)

================================================================================
TRAINING CLASSICAL MODELS WITH TFIDF FEATURES
================================================================================

1. Training Decision Tree with GridSearchCV...
   Best params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10}
   Accuracy: 0.4600
   F1-macro: 0.4521

2. Training KNN with GridSearchCV...
   Best params: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}
   Accuracy: 0.3850
   F1-macro: 0.2799

3. Training Logistic Regression with GridSearchCV...
   Best params: {'C': 10, 'max_iter': 100, 'solver': 'liblinear'}
   Accuracy: 0.5600
   F1-macro: 0.5583

4. Training Voting Classifier (Ensemble)...
   Accuracy: 0.5150
   F1-macro: 0.4993

============================================================
EVALUATION RESULTS FOR DecisionTree (TF-IDF)
============================================================

Overall Metrics:
  Accuracy:  0.4600
  Precision: 0.4644
  Recall:    0.4600
  F1-Macro:  0.4521

Classification Report:
              precision    recall  f1-score   support

    Negative       0.41      0.45      0.43        66
     Neutral       0.48      0.61      0.54        67
    Positive       0.50      0.31      0.39        67

    accuracy                           0.46       200
   macro avg       0.46      0.46      0.45       200
weighted avg       0.46      0.46      0.45       200


============================================================
EVALUATION RESULTS FOR KNN (TF-IDF)
============================================================

Overall Metrics:
  Accuracy:  0.3850
  Precision: 0.6151
  Recall:    0.3836
  F1-Macro:  0.2799

Classification Report:
              precision    recall  f1-score   support

    Negative       0.78      0.11      0.19        66
     Neutral       0.35      0.97      0.52        67
    Positive       0.71      0.07      0.14        67

    accuracy                           0.39       200
   macro avg       0.62      0.38      0.28       200
weighted avg       0.61      0.39      0.28       200


============================================================
EVALUATION RESULTS FOR LogisticRegression (TF-IDF)
============================================================

Overall Metrics:
  Accuracy:  0.5600
  Precision: 0.5592
  Recall:    0.5600
  F1-Macro:  0.5583

Classification Report:
              precision    recall  f1-score   support

    Negative       0.59      0.56      0.57        66
     Neutral       0.57      0.64      0.60        67
    Positive       0.52      0.48      0.50        67

    accuracy                           0.56       200
   macro avg       0.56      0.56      0.56       200
weighted avg       0.56      0.56      0.56       200


============================================================
EVALUATION RESULTS FOR VotingClassifier (TF-IDF)
============================================================

Overall Metrics:
  Accuracy:  0.5150
  Precision: 0.5407
  Recall:    0.5142
  F1-Macro:  0.4993

Classification Report:
              precision    recall  f1-score   support

    Negative       0.60      0.36      0.45        66
     Neutral       0.47      0.79      0.59        67
    Positive       0.55      0.39      0.46        67

    accuracy                           0.52       200
   macro avg       0.54      0.51      0.50       200
weighted avg       0.54      0.52      0.50       200


################################################################################
WORD2VEC FEATURE PIPELINE
################################################################################

================================================================================
PREPARING WORD2VEC FEATURES
================================================================================
Training Word2Vec model...
Creating document vectors...
Word2Vec training features shape: (799, 100)
Word2Vec test features shape: (200, 100)

================================================================================
TRAINING CLASSICAL MODELS WITH WORD2VEC FEATURES
================================================================================

1. Training Decision Tree with GridSearchCV...
   Best params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2}
   Accuracy: 0.4350
   F1-macro: 0.4352

2. Training KNN with GridSearchCV...
   Best params: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}
   Accuracy: 0.4100
   F1-macro: 0.4178

3. Training Logistic Regression with GridSearchCV...
   Best params: {'C': 100, 'max_iter': 100, 'solver': 'lbfgs'}
   Accuracy: 0.5250
   F1-macro: 0.5118

4. Training Voting Classifier (Ensemble)...
   Accuracy: 0.4400
   F1-macro: 0.4401

============================================================
EVALUATION RESULTS FOR DecisionTree (Word2Vec)
============================================================

Overall Metrics:
  Accuracy:  0.4350
  Precision: 0.4367
  Recall:    0.4348
  F1-Macro:  0.4352

Classification Report:
              precision    recall  f1-score   support

    Negative       0.41      0.39      0.40        66
     Neutral       0.49      0.46      0.48        67
    Positive       0.41      0.45      0.43        67

    accuracy                           0.43       200
   macro avg       0.44      0.43      0.44       200
weighted avg       0.44      0.43      0.44       200


============================================================
EVALUATION RESULTS FOR KNN (Word2Vec)
============================================================

Overall Metrics:
  Accuracy:  0.4100
  Precision: 0.4516
  Recall:    0.4104
  F1-Macro:  0.4178

Classification Report:
              precision    recall  f1-score   support

    Negative       0.36      0.48      0.41        66
     Neutral       0.69      0.43      0.53        67
    Positive       0.31      0.31      0.31        67

    accuracy                           0.41       200
   macro avg       0.45      0.41      0.42       200
weighted avg       0.45      0.41      0.42       200


============================================================
EVALUATION RESULTS FOR LogisticRegression (Word2Vec)
============================================================

Overall Metrics:
  Accuracy:  0.5250
  Precision: 0.5428
  Recall:    0.5255
  F1-Macro:  0.5118

Classification Report:
              precision    recall  f1-score   support

    Negative       0.44      0.62      0.51        66
     Neutral       0.62      0.67      0.64        67
    Positive       0.58      0.28      0.38        67

    accuracy                           0.53       200
   macro avg       0.54      0.53      0.51       200
weighted avg       0.54      0.53      0.51       200


============================================================
EVALUATION RESULTS FOR VotingClassifier (Word2Vec)
============================================================

Overall Metrics:
  Accuracy:  0.4400
  Precision: 0.4412
  Recall:    0.4398
  F1-Macro:  0.4401

Classification Report:
              precision    recall  f1-score   support

    Negative       0.41      0.39      0.40        66
     Neutral       0.50      0.48      0.49        67
    Positive       0.41      0.45      0.43        67

    accuracy                           0.44       200
   macro avg       0.44      0.44      0.44       200
weighted avg       0.44      0.44      0.44       200


################################################################################
NEURAL NETWORK PIPELINE
################################################################################

================================================================================
PREPARING DATA FOR NEURAL NETWORK
================================================================================
Neural network training data shape: (799, 100)
Neural network test data shape: (200, 100)
Number of unique tokens: 4980

================================================================================
TRAINING CNN-LSTM NEURAL NETWORK
================================================================================

Model Architecture:
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ embedding (Embedding)           â”‚ (799, 100, 128)        â”‚     1,280,000 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d (Conv1D)                 â”‚ (799, 98, 64)          â”‚        24,640 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling1d (MaxPooling1D)    â”‚ (799, 49, 64)          â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)               â”‚ (799, 49, 64)          â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lstm (LSTM)                     â”‚ (799, 64)              â”‚        33,024 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                   â”‚ (799, 32)              â”‚         2,080 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization             â”‚ (799, 32)              â”‚           128 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout)             â”‚ (799, 32)              â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (799, 3)               â”‚            99 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 1,339,971 (5.11 MB)
 Trainable params: 1,339,907 (5.11 MB)
 Non-trainable params: 64 (256.00 B)

Training model...
Epoch 1/10
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m33s[0m 2s/step - accuracy: 0.2188 - loss: 1.2287[1m 3/23[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - accuracy: 0.2899 - loss: 1.1887[1m 6/23[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - accuracy: 0.3469 - loss: 1.1563[1m 8/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - accuracy: 0.3566 - loss: 1.1487[1m10/23[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - accuracy: 0.3593 - loss: 1.1448[1m13/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - accuracy: 0.3607 - loss: 1.1403[1m16/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 24ms/step - accuracy: 0.3641 - loss: 1.1347[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 24ms/step - accuracy: 0.3664 - loss: 1.1311[1m20/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 25ms/step - accuracy: 0.3685 - loss: 1.1280[1m22/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 25ms/step - accuracy: 0.3702 - loss: 1.1252[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 39ms/step - accuracy: 0.3908 - loss: 1.0951 - val_accuracy: 0.4500 - val_loss: 1.0951 - learning_rate: 0.0010
Epoch 2/10
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - accuracy: 0.3750 - loss: 1.1432[1m 4/23[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 17ms/step - accuracy: 0.4108 - loss: 1.0904[1m 7/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 21ms/step - accuracy: 0.4196 - loss: 1.0710[1m10/23[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 22ms/step - accuracy: 0.4296 - loss: 1.0584[1m13/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 22ms/step - accuracy: 0.4403 - loss: 1.0476[1m16/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 22ms/step - accuracy: 0.4496 - loss: 1.0398[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.4546 - loss: 1.0355[1m20/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - accuracy: 0.4588 - loss: 1.0323[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - accuracy: 0.4638 - loss: 1.0290[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 27ms/step - accuracy: 0.4951 - loss: 1.0097 - val_accuracy: 0.5125 - val_loss: 1.0850 - learning_rate: 0.0010
Epoch 3/10
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - accuracy: 0.5625 - loss: 0.8991[1m 4/23[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 18ms/step - accuracy: 0.5905 - loss: 0.8917[1m 7/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 19ms/step - accuracy: 0.5770 - loss: 0.9013[1m10/23[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 21ms/step - accuracy: 0.5733 - loss: 0.9027[1m12/23[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.5744 - loss: 0.9018[1m14/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - accuracy: 0.5754 - loss: 0.9005[1m17/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 24ms/step - accuracy: 0.5773 - loss: 0.8979[1m19/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 24ms/step - accuracy: 0.5792 - loss: 0.8953[1m21/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 25ms/step - accuracy: 0.5813 - loss: 0.8926[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 25ms/step - accuracy: 0.5826 - loss: 0.8906[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 28ms/step - accuracy: 0.5953 - loss: 0.8705 - val_accuracy: 0.4375 - val_loss: 1.0788 - learning_rate: 0.0010
Epoch 4/10
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - accuracy: 0.8438 - loss: 0.6366[1m 4/23[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 20ms/step - accuracy: 0.7975 - loss: 0.6600[1m 6/23[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 24ms/step - accuracy: 0.7886 - loss: 0.6614[1m 8/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - accuracy: 0.7811 - loss: 0.6654[1m10/23[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - accuracy: 0.7765 - loss: 0.6684[1m13/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - accuracy: 0.7766 - loss: 0.6666[1m15/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - accuracy: 0.7776 - loss: 0.6643[1m17/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 27ms/step - accuracy: 0.7796 - loss: 0.6603[1m19/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 28ms/step - accuracy: 0.7817 - loss: 0.6564[1m21/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - accuracy: 0.7841 - loss: 0.6524[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 28ms/step - accuracy: 0.7864 - loss: 0.6484[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 33ms/step - accuracy: 0.8122 - loss: 0.6049 - val_accuracy: 0.4000 - val_loss: 1.0668 - learning_rate: 0.0010
Epoch 5/10
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - accuracy: 0.9375 - loss: 0.3479[1m 4/23[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 20ms/step - accuracy: 0.9193 - loss: 0.3665[1m 7/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 20ms/step - accuracy: 0.9114 - loss: 0.3854[1m 9/23[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 22ms/step - accuracy: 0.9082 - loss: 0.3903[1m12/23[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9079 - loss: 0.3884[1m15/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 22ms/step - accuracy: 0.9091 - loss: 0.3858[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9098 - loss: 0.3817[1m21/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9100 - loss: 0.3773[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 26ms/step - accuracy: 0.9082 - loss: 0.3499 - val_accuracy: 0.5000 - val_loss: 1.0512 - learning_rate: 0.0010
Epoch 6/10
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - accuracy: 0.9375 - loss: 0.2450[1m 4/23[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 19ms/step - accuracy: 0.9570 - loss: 0.2405[1m 7/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 22ms/step - accuracy: 0.9547 - loss: 0.2437[1m 9/23[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - accuracy: 0.9520 - loss: 0.2476[1m11/23[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - accuracy: 0.9510 - loss: 0.2486[1m14/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - accuracy: 0.9512 - loss: 0.2464[1m16/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - accuracy: 0.9515 - loss: 0.2445[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 26ms/step - accuracy: 0.9521 - loss: 0.2420[1m20/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - accuracy: 0.9525 - loss: 0.2395[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 26ms/step - accuracy: 0.9535 - loss: 0.2357[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 30ms/step - accuracy: 0.9611 - loss: 0.2094 - val_accuracy: 0.4750 - val_loss: 1.0363 - learning_rate: 0.0010
Epoch 7/10
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - accuracy: 1.0000 - loss: 0.0710[1m 4/23[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 18ms/step - accuracy: 0.9824 - loss: 0.1069[1m 6/23[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9826 - loss: 0.1099[1m 9/23[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9836 - loss: 0.1110[1m12/23[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 22ms/step - accuracy: 0.9837 - loss: 0.1115[1m16/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 21ms/step - accuracy: 0.9833 - loss: 0.1120[1m19/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 20ms/step - accuracy: 0.9831 - loss: 0.1116[1m22/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 20ms/step - accuracy: 0.9824 - loss: 0.1121[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 34ms/step - accuracy: 0.9777 - loss: 0.1142 - val_accuracy: 0.5375 - val_loss: 1.0098 - learning_rate: 0.0010
Epoch 8/10
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m11s[0m 533ms/step - accuracy: 0.9688 - loss: 0.0970[1m 3/23[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 40ms/step - accuracy: 0.9688 - loss: 0.1065  [1m 5/23[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - accuracy: 0.9688 - loss: 0.1074[1m 9/23[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - accuracy: 0.9713 - loss: 0.1043[1m12/23[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9714 - loss: 0.1030[1m15/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9722 - loss: 0.1011[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9729 - loss: 0.0989[1m20/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9736 - loss: 0.0973[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - accuracy: 0.9740 - loss: 0.0956[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 27ms/step - accuracy: 0.9777 - loss: 0.0837 - val_accuracy: 0.5750 - val_loss: 0.9880 - learning_rate: 0.0010
Epoch 9/10
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - accuracy: 1.0000 - loss: 0.0771[1m 4/23[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 18ms/step - accuracy: 1.0000 - loss: 0.0693[1m 7/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 19ms/step - accuracy: 0.9952 - loss: 0.0708[1m10/23[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 20ms/step - accuracy: 0.9914 - loss: 0.0728[1m12/23[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 21ms/step - accuracy: 0.9901 - loss: 0.0735[1m15/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 21ms/step - accuracy: 0.9894 - loss: 0.0730[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 22ms/step - accuracy: 0.9892 - loss: 0.0723[1m20/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 22ms/step - accuracy: 0.9890 - loss: 0.0721[1m22/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 23ms/step - accuracy: 0.9890 - loss: 0.0717[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 27ms/step - accuracy: 0.9861 - loss: 0.0697 - val_accuracy: 0.5875 - val_loss: 0.9727 - learning_rate: 0.0010
Epoch 10/10
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - accuracy: 1.0000 - loss: 0.0175[1m 5/23[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 18ms/step - accuracy: 0.9959 - loss: 0.0504[1m 8/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 18ms/step - accuracy: 0.9941 - loss: 0.0522[1m11/23[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 20ms/step - accuracy: 0.9940 - loss: 0.0509[1m13/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 21ms/step - accuracy: 0.9941 - loss: 0.0499[1m15/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 22ms/step - accuracy: 0.9943 - loss: 0.0491[1m17/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9946 - loss: 0.0483[1m20/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 23ms/step - accuracy: 0.9946 - loss: 0.0480[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - accuracy: 0.9944 - loss: 0.0485[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 27ms/step - accuracy: 0.9930 - loss: 0.0526 - val_accuracy: 0.5625 - val_loss: 0.9597 - learning_rate: 0.0010
[1m1/7[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 160ms/step[1m7/7[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 27ms/step [1m7/7[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 29ms/step

Test Loss: 0.9880
Test Accuracy: 0.5250
Test F1-Macro: 0.5272

============================================================
EVALUATION RESULTS FOR CNN-LSTM Neural Network
============================================================

Overall Metrics:
  Accuracy:  0.5250
  Precision: 0.5383
  Recall:    0.5253
  F1-Macro:  0.5272

Classification Report:
              precision    recall  f1-score   support

    Negative       0.52      0.58      0.55        66
     Neutral       0.65      0.49      0.56        67
    Positive       0.45      0.51      0.48        67

    accuracy                           0.53       200
   macro avg       0.54      0.53      0.53       200
weighted avg       0.54      0.53      0.53       200


================================================================================
MODEL COMPARISON SUMMARY
================================================================================

  Feature Type              Model Accuracy F1-Macro Precision Recall
        TF-IDF LogisticRegression   0.5600   0.5583    0.5592 0.5600
Neural Network           CNN-LSTM   0.5250   0.5272    0.5383 0.5253
      Word2Vec LogisticRegression   0.5250   0.5118    0.5428 0.5255
        TF-IDF   VotingClassifier   0.5150   0.4993    0.5407 0.5142
        TF-IDF       DecisionTree   0.4600   0.4521    0.4644 0.4600
      Word2Vec   VotingClassifier   0.4400   0.4401    0.4412 0.4398
      Word2Vec       DecisionTree   0.4350   0.4352    0.4367 0.4348
      Word2Vec                KNN   0.4100   0.4178    0.4516 0.4104
        TF-IDF                KNN   0.3850   0.2799    0.6151 0.3836

Comparison table saved to 'f1000_model_comparison.csv'

================================================================================
PLOTTING ROC CURVES
================================================================================

================================================================================
PIPELINE COMPLETED SUCCESSFULLY!
================================================================================
Completed at: 2025-11-20 10:35:34

================================================================================
BEST MODEL
================================================================================
Best performing model: LogisticRegression with TF-IDF features
  - Accuracy: 0.5600
  - F1-Macro: 0.5583

âœ… Pipeline executed successfully!
